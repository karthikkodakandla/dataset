{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_karthik.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikkodakandla/dataset/blob/master/Assignment2_karthik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bwMIcDiG-Mk",
        "outputId": "2f894e13-169b-43cd-c0d6-3bbfda13ff8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Activation\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzdIkZmjz7f0"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAoX9oNL7-3e",
        "outputId": "fc871db4-e068-471c-fd03-aa5ebffaa447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\"4/4gGieupuu9nlrt02jqlN2V25fX1C5GFUct7zXuezrKtHLgmzYS6Tyl0\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4/4gGieupuu9nlrt02jqlN2V25fX1C5GFUct7zXuezrKtHLgmzYS6Tyl0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K57yprzmHCtG",
        "outputId": "146b41c3-7c0d-457a-df25-1b44b44df3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "col_names = ['image','label']\n",
        "df = pd.read_csv('/content/drive/My Drive/Flower_images/Flower_image/classlabels.txt', header =None, names = col_names)\n",
        "df = df.sort_values(by='image')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JFT_00001.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JFT_00002.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JFT_00003.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JFT_00004.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>JFT_00005.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>JFT_01475.jpg</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>JFT_01476.jpg</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>JFT_01477.jpg</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>JFT_01478.jpg</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>JFT_01479.jpg</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1479 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              image  label\n",
              "0     JFT_00001.jpg      1\n",
              "1     JFT_00002.jpg      1\n",
              "2     JFT_00003.jpg      1\n",
              "3     JFT_00004.jpg      1\n",
              "558   JFT_00005.jpg      1\n",
              "...             ...    ...\n",
              "555   JFT_01475.jpg     30\n",
              "1477  JFT_01476.jpg     30\n",
              "1478  JFT_01477.jpg     30\n",
              "556   JFT_01478.jpg     30\n",
              "557   JFT_01479.jpg     30\n",
              "\n",
              "[1479 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ31VatI7-N_",
        "outputId": "7085ebaf-437c-403f-fb89-19d55d679b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6     70\n",
              "28    68\n",
              "23    67\n",
              "13    66\n",
              "4     66\n",
              "2     65\n",
              "7     64\n",
              "18    63\n",
              "29    63\n",
              "20    61\n",
              "27    61\n",
              "24    60\n",
              "10    60\n",
              "25    56\n",
              "19    55\n",
              "14    54\n",
              "5     54\n",
              "22    49\n",
              "12    48\n",
              "9     46\n",
              "17    45\n",
              "3     41\n",
              "21    38\n",
              "11    36\n",
              "26    35\n",
              "8     28\n",
              "16    24\n",
              "15    13\n",
              "30    12\n",
              "1     11\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqAsvwsYY1n_"
      },
      "source": [
        "import os\n",
        "directory ='/content/drive/My Drive/Flower_images/Flower_image/jpg/'\n",
        "images = sorted(os.listdir(directory))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRCJcwTKCasW",
        "outputId": "b493c740-6e16-43da-991c-3aac705280ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JagQTckUfy2T",
        "outputId": "8bfed591-e024-4a03-9126-52acf9cf64e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = []\n",
        "import time\n",
        "from progressbar import ProgressBar\n",
        "pbar = ProgressBar()\n",
        "\n",
        "for imgs in pbar(images):\n",
        "  img_path = os.path.join(directory, imgs)\n",
        "  img = load_img(img_path, color_mode = 'rgb', target_size = (32, 32))\n",
        "  img = img_to_array(img).astype('float32')/255\n",
        "  x_train.append(img)\n",
        " \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (1479 of 1479) |####################| Elapsed Time: 0:04:51 Time:  0:04:51\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPElU1-dgUnb"
      },
      "source": [
        "y=np.array(df['label'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-vVzXNeMeMd"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y=pd.DataFrame(enc.fit_transform(df[['label']]).toarray())\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqjGedYXzZhF",
        "outputId": "8f55aabf-aa24-454e-ee83-9434e1df4ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzGqKZnvzbRN",
        "outputId": "542073ec-6ee4-439b-a820-7fb11ed28bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1479, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALo8Md6CMj4t"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y, test_size = 0.25)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_b7Hv1c1MAx"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ46lX7j1rBi",
        "outputId": "cba1a484-c825-46a2-fc45-bbbc2c0458f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "NUM_CLASSES = 30\n",
        "IMG_ROW,IMG_COL = 32,32\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "def resnet():\n",
        "    # Build a Sequential Model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Inception module\n",
        "    model.add(ResNet50(include_top=False, input_shape=(IMG_ROW, IMG_COL, 3)))\n",
        "    \n",
        "    # Flatten *** Most Important *** Never forget to flatten a conv output before dense\n",
        "    ## This is necessary for resolving dimension errors \n",
        "    model.add(Flatten()) \n",
        "    \n",
        "    # Fully connected layer\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.02))\n",
        "    \n",
        "    # Fully connected layer\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.02))\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "    \n",
        "    # Set trainable false to use pretrained weights and not update them\n",
        "    model.layers[0].trainable = False\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer = 'adam', loss ='categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model\n",
        "model = resnet()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p66a7WBKfGJB"
      },
      "source": [
        "x_train = np.array(x_train)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra1PM7Zj3vJ_"
      },
      "source": [
        "# Define training params\n",
        "batch_size = 164\n",
        "epochs = 10 # Set to 1 for demo, for good results set 100, Running for 100 epochs will take time.\n",
        "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "red_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZiKcgSj320z"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images ideally true\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6tPmxJH1xfx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul94JUPI4mKk"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "adam_fine = Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #20x smaller than standard\n",
        "model.compile(optimizer=adam_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp82yAdv4p3O",
        "outputId": "6a8b29be-a770-4ee2-c959-10dd91e1f8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                15390     \n",
            "=================================================================\n",
            "Total params: 26,226,078\n",
            "Trainable params: 26,172,958\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-U5IdNzOZ5K"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gbIXLI-Opnl"
      },
      "source": [
        "x_test = np.array(x_test)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PUV5QkvvxYx"
      },
      "source": [
        "# Train the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hNh1dUc4HE1",
        "outputId": "bcbc05b4-132e-4dad-9206-d1d498a0ed4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (x_test,y_test),\n",
        "                              verbose = 1,steps_per_epoch=x_train.shape[0] // batch_size)\n",
        "# model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-a54ef53137d7>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 61s 10s/step - loss: 3.7930 - accuracy: 0.0640 - val_loss: 3.9856 - val_accuracy: 0.0432\n",
            "Epoch 2/10\n",
            "3/6 [==============>...............] - ETA: 23s - loss: 3.4209 - accuracy: 0.0894"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6mwSb9iPXzR"
      },
      "source": [
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(history.epoch, np.array(history.history['accuracy']),\n",
        "           label='Train Loss')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_accuracy']),\n",
        "           label = 'Val loss')\n",
        "  plt.legend()\n",
        "  plt.ylim([0, 1])\n",
        "\n",
        "plot_history(History)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE7T9vCXU0Zq"
      },
      "source": [
        "print(max(History.history['val_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XybStCKhSh1B"
      },
      "source": [
        "test_img_10 = plt.imread(\"/content/class_10.jpg\") \n",
        "test_img_28 = plt.imread(\"/content/class_28.jpg\")\n",
        "test_img_29 = plt.imread('/content/class_29.jpg')\n",
        "test_img = plt.imread('/content/fly orchid 1.jpg')\n",
        "plt.imshow(test_img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf6CGhm9Tb_I"
      },
      "source": [
        "from skimage.transform import resize\n",
        "resized_image = resize(test_img, (32,32,3))\n",
        "predictions = model.predict(np.array( [resized_image] ))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7HuyANAT18v"
      },
      "source": [
        "predictions.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}